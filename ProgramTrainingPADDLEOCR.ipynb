{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3vahbgSf1Jz"
      },
      "outputs": [],
      "source": [
        "# KONFIGURASI EKSTRAKSI DATASET DARI DRIVE\n",
        "\n",
        "print(\"üöÄ SEL 0: Ekstraksi Dataset dari Google Drive...\")\n",
        "\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Path file zip di Drive dan tujuan ekstraksi\n",
        "DRIVE_ZIP_PATH = \"/content/drive/MyDrive/datasetfix2.zip\"  # ‚ö†Ô∏è Ganti dengan path zip Anda\n",
        "EXTRACT_TO = \"/content/datasetfix2\"  # Path ekstraksi (sama seperti di Kaggle)\n",
        "\n",
        "# 3. Hapus folder lama jika ada\n",
        "if os.path.exists(EXTRACT_TO):\n",
        "    shutil.rmtree(EXTRACT_TO)\n",
        "    print(f\"‚ÑπÔ∏è Folder lama '{EXTRACT_TO}' dihapus\")\n",
        "\n",
        "# 4. Ekstrak zip\n",
        "print(f\"‚è≥ Mengekstrak {DRIVE_ZIP_PATH} ke {EXTRACT_TO}...\")\n",
        "with zipfile.ZipFile(DRIVE_ZIP_PATH, 'r') as zip_ref:\n",
        "    zip_ref.extractall(EXTRACT_TO)\n",
        "\n",
        "# 5. Verifikasi\n",
        "print(\"‚úÖ Ekstraksi selesai. Struktur folder:\")\n",
        "!ls -lh \"{EXTRACT_TO}\" | head -n 10\n",
        "\n",
        "# 6. Set variabel path asli program (PERBAIKAN ERROR DI SINI)\n",
        "KAGGLE_COCO_INPUT_DIR_SEL2 = EXTRACT_TO  # Variabel sesuai program asli\n",
        "print(f\"\\nüéâ SEL 0: Dataset siap di path: {KAGGLE_COCO_INPUT_DIR_SEL2}\")  # Perbaikan nama variabel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PENGATURAN PADDLEOCR DAN CHECKPOINT\n",
        "\n",
        "print(\"üöÄ SEL 1: Memulai Pengaturan Lingkungan di Colab...\")\n",
        "import os\n",
        "import shutil\n",
        "# ... (import lain yang relevan untuk SEL 1) ...\n",
        "\n",
        "os.environ['OMP_NUM_THREADS'] = '1'\n",
        "print(\"‚úÖ Environment variable OMP_NUM_THREADS=1 telah di-set.\")\n",
        "\n",
        "print(\"\\nüîÑ Menginstal dependensi (jika diperlukan)...\")\n",
        "# (Baris-baris !pip install Anda tetap di sini)\n",
        "# Contoh:\n",
        "!pip install --quiet \"protobuf==3.20.3\"\n",
        "!python -m pip install --quiet paddlepaddle==2.6.1 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
        "!pip install --quiet \"paddleocr==2.9.1\" lmdb rapidfuzz Pillow opencv-python-headless\n",
        "print(\"‚úÖ Dependensi (semoga) terinstal.\")\n",
        "# (Verifikasi instalasi Anda)\n",
        "\n",
        "# --- Modifikasi pada bagian Clone Repository ---\n",
        "base_working_dir_sel1_safe = \"/content/\"\n",
        "paddle_ocr_official_dir_sel1_safe = os.path.join(base_working_dir_sel1_safe, \"PaddleOCR_Official\")\n",
        "\n",
        "if not os.path.exists(paddle_ocr_official_dir_sel1_safe):\n",
        "    print(f\"\\nDirektori '{paddle_ocr_official_dir_sel1_safe}' tidak ditemukan. Melakukan clone...\")\n",
        "    current_dir_sel1_safe = os.getcwd()\n",
        "    if current_dir_sel1_safe != base_working_dir_sel1_safe:\n",
        "        # Pastikan base_working_dir_sel1_safe ada jika kita chdir ke sana\n",
        "        os.makedirs(base_working_dir_sel1_safe, exist_ok=True)\n",
        "        os.chdir(base_working_dir_sel1_safe)\n",
        "    !git clone https://github.com/PaddlePaddle/PaddleOCR.git \"{paddle_ocr_official_dir_sel1_safe}\"\n",
        "    if current_dir_sel1_safe != base_working_dir_sel1_safe and os.path.exists(current_dir_sel1_safe):\n",
        "        os.chdir(current_dir_sel1_safe) # Kembali jika perlu dan path masih valid\n",
        "    print(f\"‚úÖ Repository PaddleOCR berhasil di-clone ke {paddle_ocr_official_dir_sel1_safe}.\")\n",
        "else:\n",
        "    print(f\"‚úÖ Direktori '{paddle_ocr_official_dir_sel1_safe}' sudah ada. Clone dilewati.\")\n",
        "\n",
        "# Pindah ke direktori PaddleOCR Resmi\n",
        "try:\n",
        "    if os.getcwd() == base_working_dir_sel1_safe: # Jika kita masih di /content/\n",
        "        os.chdir(paddle_ocr_official_dir_sel1_safe)\n",
        "    elif not os.getcwd().endswith(\"PaddleOCR_Official\"): # Jika kita di tempat lain, coba chdir\n",
        "        os.chdir(paddle_ocr_official_dir_sel1_safe)\n",
        "\n",
        "    print(f\"‚úÖ Direktori kerja saat ini: {os.getcwd()}\")\n",
        "    if not os.getcwd().endswith(\"PaddleOCR_Official\"):\n",
        "        print(f\"‚ö†Ô∏è Peringatan: Direktori kerja mungkin salah. Seharusnya diakhiri 'PaddleOCR_Official'.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå ERROR: Direktori '{paddle_ocr_official_dir_sel1_safe}' tidak ditemukan untuk diubah.\")\n",
        "    raise\n",
        "print(\"\\nüéâ SEL 1: Pengaturan Lingkungan Selesai!\")"
      ],
      "metadata": {
        "id": "KG8wQU9BgGKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KONFIGURASI PENGGUNA & AKSES DATASET COCO JSON\n",
        "\n",
        "print(\"\\n\\nüöÄ SEL 2: Konfigurasi Pengguna & Akses Dataset COCO JSON Asli...\")\n",
        "\n",
        "# --- PENGATURAN PENGGUNA ---\n",
        "# Gunakan path yang sudah diekstrak di SEL 0\n",
        "COLAB_COCO_INPUT_DIR_SEL2 = '/content/datasetfix2'  # Path hasil ekstraksi SEL 0\n",
        "TRAIN_COCO_JSON_RELPATH_SEL2 = \"train/_annotations.coco.json\"\n",
        "VALID_COCO_JSON_RELPATH_SEL2 = \"valid/_annotations.coco.json\"\n",
        "\n",
        "# Direktori processing (tetap sama)\n",
        "COLAB_PROCESSED_RECO_DATA_DIR_SEL2 = '/content/processed_recognition_data'\n",
        "\n",
        "# --- Validasi Path ---\n",
        "print(f\"‚ÑπÔ∏è Path dataset (hasil ekstraksi): {COLAB_COCO_INPUT_DIR_SEL2}\")\n",
        "print(f\"‚ÑπÔ∏è Target processed data: {COLAB_PROCESSED_RECO_DATA_DIR_SEL2}\")\n",
        "\n",
        "# Verifikasi folder hasil ekstraksi SEL 0\n",
        "if not os.path.isdir(COLAB_COCO_INPUT_DIR_SEL2):\n",
        "    print(f\"\\n‚ùå ERROR: Folder hasil ekstraksi tidak ditemukan di: {COLAB_COCO_INPUT_DIR_SEL2}\")\n",
        "    print(\"Pastikan SEL 0 sudah dijalankan dan ekstraksi berhasil!\")\n",
        "    print(\"Isi /content/:\")\n",
        "    !ls -lh /content/\n",
        "    raise SystemExit(\"Dataset belum diekstrak\")\n",
        "\n",
        "# Verifikasi file COCO\n",
        "required_files = [\n",
        "    os.path.join(COLAB_COCO_INPUT_DIR_SEL2, TRAIN_COCO_JSON_RELPATH_SEL2),\n",
        "    os.path.join(COLAB_COCO_INPUT_DIR_SEL2, VALID_COCO_JSON_RELPATH_SEL2)\n",
        "]\n",
        "\n",
        "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
        "if missing_files:\n",
        "    print(f\"\\n‚ùå File COCO JSON tidak ditemukan:\")\n",
        "    for f in missing_files:\n",
        "        print(f\"- {f}\")\n",
        "    print(\"\\nStruktur folder yang ada:\")\n",
        "    !tree -L 3 \"{COLAB_COCO_INPUT_DIR_SEL2}\"\n",
        "    raise SystemExit(\"File annotasi COCO tidak lengkap\")\n",
        "\n",
        "# Persiapan folder output\n",
        "if os.path.exists(COLAB_PROCESSED_RECO_DATA_DIR_SEL2):\n",
        "    shutil.rmtree(COLAB_PROCESSED_RECO_DATA_DIR_SEL2)\n",
        "\n",
        "os.makedirs(os.path.join(COLAB_PROCESSED_RECO_DATA_DIR_SEL2, \"train_images_cropped\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(COLAB_PROCESSED_RECO_DATA_DIR_SEL2, \"val_images_cropped\"), exist_ok=True)\n",
        "\n",
        "print(\"\\n‚úÖ Struktur dataset valid:\")\n",
        "!tree -L 2 \"{COLAB_COCO_INPUT_DIR_SEL2}\" | head -n 10\n",
        "print(f\"\\nüéâ SEL 2: Konfigurasi Dataset COCO JSON Selesai!\")"
      ],
      "metadata": {
        "id": "W23KeZVZgXWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PRA-PEMROSESAN COCO JSON (ANOTASI KARAKTER) KE FORMAT RECOGNITION\n",
        "\n",
        "print(\"\\n\\nüöÄ SEL 3: Memulai Pra-Pemrosesan COCO JSON (Anotasi Karakter)...\")\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import shutil\n",
        "\n",
        "# Path output dari sel ini - diubah ke path Colab\n",
        "output_train_label_reco_file_sel3 = os.path.join(COLAB_PROCESSED_RECO_DATA_DIR_SEL2, \"train_label_recognition.txt\")\n",
        "output_val_label_reco_file_sel3 = os.path.join(COLAB_PROCESSED_RECO_DATA_DIR_SEL2, \"val_label_recognition.txt\")\n",
        "output_train_imgs_cropped_dir_sel3 = os.path.join(COLAB_PROCESSED_RECO_DATA_DIR_SEL2, \"train_images_cropped\")\n",
        "output_val_imgs_cropped_dir_sel3 = os.path.join(COLAB_PROCESSED_RECO_DATA_DIR_SEL2, \"val_images_cropped\")\n",
        "\n",
        "# --- Definisi fungsi coco_char_annot_to_line_recognition ---\n",
        "def coco_char_annot_to_line_recognition(\n",
        "    coco_json_relative_path, base_dir_of_coco_input,\n",
        "    output_dir_for_cropped_lines, output_path_for_rec_label,\n",
        "    cropped_img_subfolder_name_for_label\n",
        "):\n",
        "    full_coco_json_path = os.path.join(base_dir_of_coco_input, coco_json_relative_path)\n",
        "    if not os.path.exists(full_coco_json_path):\n",
        "        print(f\"‚ÑπÔ∏è Info: File COCO JSON '{full_coco_json_path}' tidak ditemukan. Dilewati.\")\n",
        "        return 0\n",
        "    print(f\"\\n‚öôÔ∏è Memproses COCO JSON (anotasi karakter): {full_coco_json_path}\")\n",
        "    with open(full_coco_json_path, 'r', encoding='utf-8') as f_c_char:\n",
        "        coco_data_char = json.load(f_c_char)\n",
        "\n",
        "    image_id_to_info = {img['id']: img for img in coco_data_char.get('images', [])}\n",
        "    category_id_to_char = {cat['id']: cat['name'] for cat in coco_data_char.get('categories', [])}\n",
        "    annotations_by_image = {}\n",
        "\n",
        "    for ann_char in coco_data_char.get('annotations', []):\n",
        "        img_id_char = ann_char.get('image_id')\n",
        "        if img_id_char not in annotations_by_image:\n",
        "            annotations_by_image[img_id_char] = []\n",
        "        annotations_by_image[img_id_char].append(ann_char)\n",
        "\n",
        "    if not annotations_by_image:\n",
        "        print(f\"  ‚ö†Ô∏è Tidak ada anotasi di {full_coco_json_path}.\")\n",
        "        return 0\n",
        "\n",
        "    rec_labels_written_count = 0\n",
        "\n",
        "    with open(output_path_for_rec_label, 'w', encoding='utf-8') as f_rec_out_char:\n",
        "        for img_idx, (img_id, char_ann_list) in enumerate(annotations_by_image.items()):\n",
        "            if img_id not in image_id_to_info:\n",
        "                continue\n",
        "\n",
        "            image_details_char = image_id_to_info[img_id]\n",
        "            original_img_fname = image_details_char['file_name']\n",
        "            coco_json_dir_path = os.path.dirname(full_coco_json_path)\n",
        "            path_to_original_img_char = os.path.join(coco_json_dir_path, original_img_fname)\n",
        "\n",
        "            if not os.path.exists(path_to_original_img_char):\n",
        "                path_to_original_img_char = os.path.join(base_dir_of_coco_input, original_img_fname)\n",
        "                if not os.path.exists(path_to_original_img_char):\n",
        "                    print(f\"  ‚ùå Gbr asli '{original_img_fname}' TDK ditemukan (Path: {path_to_original_img_char}). Dilewati.\")\n",
        "                    continue\n",
        "\n",
        "            if not char_ann_list:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                char_ann_list.sort(key=lambda ann: ann['bbox'][0])\n",
        "            except Exception as e_sort_bbox:\n",
        "                print(f\"  ‚ö†Ô∏è Error sorting '{original_img_fname}': {e_sort_bbox}. Dilewati.\")\n",
        "                continue\n",
        "\n",
        "            assembled_text_line = \"\".join([category_id_to_char.get(ann.get('category_id'),'') for ann in char_ann_list])\n",
        "            if not assembled_text_line.strip():\n",
        "                continue\n",
        "\n",
        "            all_char_x_coords, all_char_y_coords = [], []\n",
        "            valid_points_found = True\n",
        "\n",
        "            for char_ann_item in char_ann_list:\n",
        "                bbox_char = char_ann_item.get('bbox')\n",
        "                x_c, y_c, w_c, h_c = bbox_char if bbox_char and len(bbox_char) == 4 else (None,None,None,None)\n",
        "                if x_c is None:\n",
        "                    valid_points_found = False\n",
        "                    break\n",
        "                all_char_x_coords.extend([x_c, x_c + w_c])\n",
        "                all_char_y_coords.extend([y_c, y_c + h_c])\n",
        "\n",
        "            if not valid_points_found or not all_char_x_coords:\n",
        "                print(f\"  ‚ö†Ô∏è Bbox karakter tdk valid u/ '{original_img_fname}'. Dilewati.\")\n",
        "                continue\n",
        "\n",
        "            line_bbox_min_x, line_bbox_min_y = int(min(all_char_x_coords)), int(min(all_char_y_coords))\n",
        "            line_bbox_max_x, line_bbox_max_y = int(max(all_char_x_coords)), int(max(all_char_y_coords))\n",
        "\n",
        "            try:\n",
        "                pil_orig_img = Image.open(path_to_original_img_char).convert(\"RGB\")\n",
        "                img_w_o, img_h_o = pil_orig_img.size\n",
        "\n",
        "                crop_x1, crop_y1 = max(0, line_bbox_min_x), max(0, line_bbox_min_y)\n",
        "                crop_x2, crop_y2 = min(img_w_o, line_bbox_max_x), min(img_h_o, line_bbox_max_y)\n",
        "\n",
        "                if crop_x2 <= crop_x1 or crop_y2 <= crop_y1:\n",
        "                    print(f\"  ‚ö†Ô∏è Bbox baris tdk valid u/ '{original_img_fname}'. Dilewati.\")\n",
        "                    continue\n",
        "\n",
        "                pil_cropped_line = pil_orig_img.crop((crop_x1, crop_y1, crop_x2, crop_y2))\n",
        "\n",
        "                if pil_cropped_line.width < 2 or pil_cropped_line.height < 2:\n",
        "                    print(f\"  ‚ö†Ô∏è Crop terlalu kecil u/ '{original_img_fname}'. Dilewati.\")\n",
        "                    continue\n",
        "\n",
        "                cropped_line_fname = f\"linecrop_{img_id}_{char_ann_list[0].get('id', img_idx)}.png\"\n",
        "                path_to_save_cropped_line_img = os.path.join(output_dir_for_cropped_lines, cropped_line_fname)\n",
        "                pil_cropped_line.save(path_to_save_cropped_line_img)\n",
        "\n",
        "                relative_path_label = os.path.join(cropped_img_subfolder_name_for_label, cropped_line_fname).replace(\"\\\\\",\"/\")\n",
        "                f_rec_out_char.write(f\"{relative_path_label}\\t{assembled_text_line}\\n\")\n",
        "                rec_labels_written_count += 1\n",
        "\n",
        "                if rec_labels_written_count > 0 and rec_labels_written_count % 50 == 0:\n",
        "                    print(f\"    ... {rec_labels_written_count} label recognition dibuat...\")\n",
        "\n",
        "            except Exception as e_img_proc:\n",
        "                print(f\"  ‚ùå Error cropping/saving '{original_img_fname}': {e_img_proc}\")\n",
        "\n",
        "    print(f\"  ‚úÖ Selesai {full_coco_json_path}. Total {rec_labels_written_count} label dibuat.\")\n",
        "    return rec_labels_written_count\n",
        "# --- Akhir Definisi Fungsi ---\n",
        "\n",
        "num_train_labels_final_sel3 = coco_char_annot_to_line_recognition(\n",
        "    TRAIN_COCO_JSON_RELPATH_SEL2, COLAB_COCO_INPUT_DIR_SEL2,\n",
        "    output_train_imgs_cropped_dir_sel3, output_train_label_reco_file_sel3,\n",
        "    \"train_images_cropped\"\n",
        ")\n",
        "\n",
        "if VALID_COCO_JSON_RELPATH_SEL2 and VALID_COCO_JSON_RELPATH_SEL2.strip():\n",
        "    num_val_labels_final_sel3 = coco_char_annot_to_line_recognition(\n",
        "        VALID_COCO_JSON_RELPATH_SEL2, COLAB_COCO_INPUT_DIR_SEL2,\n",
        "        output_val_imgs_cropped_dir_sel3, output_val_label_reco_file_sel3,\n",
        "        \"val_images_cropped\"\n",
        "    )\n",
        "else:\n",
        "    num_val_labels_final_sel3 = 0\n",
        "    print(\"‚ÑπÔ∏è Tdk ada set validasi COCO, pemrosesan validasi dilewati.\")\n",
        "\n",
        "if num_train_labels_final_sel3 == 0:\n",
        "    print(\"‚ùå ERROR: Tdk ada data training dibuat.\")\n",
        "    raise SystemExit(\"Transformasi training gagal.\")\n",
        "\n",
        "print(f\"\\nüîç Verifikasi '{output_train_label_reco_file_sel3}' (5 baris):\")\n",
        "if os.path.exists(output_train_label_reco_file_sel3):\n",
        "    with open(output_train_label_reco_file_sel3, 'r', encoding='utf-8') as f_v_r_sel3:\n",
        "        [print(f\"  {lvr_sel3.strip()}\") for i_vr_sel3, lvr_sel3 in enumerate(f_v_r_sel3) if i_vr_sel3 < 5]\n",
        "\n",
        "print(\"\\nüéâ SEL 3: Pra-Pemrosesan COCO JSON (Karakter) Selesai!\")"
      ],
      "metadata": {
        "id": "b2VPuVT8gbSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PEMBUATAN FILE custom_char_dict.txt (KAMUS LARAKTER)\n",
        "\n",
        "print(\"\\n\\nüöÄ SEL 4: Memulai Pembuatan Kamus Karakter...\")\n",
        "path_char_dict_output_sel4 = os.path.join(COLAB_PROCESSED_RECO_DATA_DIR_SEL2, \"custom_char_dict.txt\")\n",
        "SETTING_USE_SPACE_CHAR_SEL4 = True  # Set True untuk menyertakan spasi\n",
        "collected_chars_final_sel4 = set()\n",
        "\n",
        "# --- Implementasi Fungsi yang Hilang ---\n",
        "def generate_char_dict_final_sel4(label_file, char_set):\n",
        "    \"\"\"Mengumpulkan karakter unik dari file label\"\"\"\n",
        "    if not os.path.exists(label_file):\n",
        "        print(f\"‚ÑπÔ∏è File label '{label_file}' tidak ditemukan\")\n",
        "        return\n",
        "\n",
        "    print(f\"üîç Memproses karakter dari: {label_file}\")\n",
        "    with open(label_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split('\\t')\n",
        "            if len(parts) >= 2:  # Format: path_image\\ttext_label\n",
        "                text = parts[1]\n",
        "                for char in text:\n",
        "                    char_set.add(char)\n",
        "\n",
        "    print(f\"  Ditemukan {len(char_set)} karakter unik\")\n",
        "\n",
        "# --- Proses File Training dan Validasi ---\n",
        "print(\"‚è≥ Mengumpulkan karakter dari file label...\")\n",
        "generate_char_dict_final_sel4(output_train_label_reco_file_sel3, collected_chars_final_sel4)\n",
        "\n",
        "if os.path.exists(output_val_label_reco_file_sel3):\n",
        "    generate_char_dict_final_sel4(output_val_label_reco_file_sel3, collected_chars_final_sel4)\n",
        "\n",
        "# --- Tambahkan Spasi Jika Diperlukan ---\n",
        "if SETTING_USE_SPACE_CHAR_SEL4:\n",
        "    collected_chars_final_sel4.add(' ')\n",
        "    print(\"‚ÑπÔ∏è Menambahkan karakter spasi\")\n",
        "\n",
        "# --- Validasi dan Simpan Kamus ---\n",
        "if not collected_chars_final_sel4 or (len(collected_chars_final_sel4) == 1 and ' ' in collected_chars_final_sel4):\n",
        "    print(\"‚ùå ERROR: Tidak ada karakter yang valid untuk kamus\")\n",
        "    print(\"Kemungkinan penyebab:\")\n",
        "    print(\"1. File label training/validasi kosong\")\n",
        "    print(\"2. Path file label tidak benar\")\n",
        "    print(f\"   - Training: {output_train_label_reco_file_sel3} (ada: {os.path.exists(output_train_label_reco_file_sel3)})\")\n",
        "    print(f\"   - Validasi: {output_val_label_reco_file_sel3} (ada: {os.path.exists(output_val_label_reco_file_sel3)})\")\n",
        "    raise SystemExit(\"Pembuatan kamus karakter gagal\")\n",
        "\n",
        "# --- Urutkan dan Simpan ---\n",
        "sorted_chars_final_sel4 = sorted(list(collected_chars_final_sel4))\n",
        "with open(path_char_dict_output_sel4, 'w', encoding='utf-8') as f:\n",
        "    for char in sorted_chars_final_sel4:\n",
        "        f.write(f\"{char}\\n\")\n",
        "\n",
        "# --- Verifikasi Final ---\n",
        "print(f\"\\n‚úÖ Kamus karakter disimpan di: {path_char_dict_output_sel4}\")\n",
        "print(f\"   Total karakter unik: {len(sorted_chars_final_sel4)}\")\n",
        "print(\"   Contoh karakter (max 100):\", ''.join(sorted_chars_final_sel4[:100]))\n",
        "\n",
        "print(\"\\nüéâ SEL 4: Pembuatan Kamus Karakter Selesai!\")"
      ],
      "metadata": {
        "id": "Pf9whzOAgdfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODIFIKASI FILE KONFIGURASI YAML\n",
        "\n",
        "print(\"\\n\\nüöÄ SEL 6: Modifikasi File Konfigurasi YAML untuk Arsitektur PP-OCRv4 Mobile...\")\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "# --- Verifikasi Variabel Penting dari Sel Sebelumnya (TETAP SAMA) ---\n",
        "required_vars_sel6_cpu_chkpt = [\n",
        "    'COLAB_PROCESSED_RECO_DATA_DIR_SEL2',\n",
        "    'output_train_label_reco_file_sel3',\n",
        "    'output_val_label_reco_file_sel3',\n",
        "    'num_val_labels_final_sel3',\n",
        "    'path_char_dict_output_sel4',\n",
        "    'SETTING_USE_SPACE_CHAR_SEL4',\n",
        "    'sorted_chars_final_sel4'\n",
        "]\n",
        "print(\"üîç Memeriksa ketersediaan variabel yang dibutuhkan...\")\n",
        "all_vars_present_sel6_cpu_chkpt = True\n",
        "for var_name_sel6_chkpt in required_vars_sel6_cpu_chkpt:\n",
        "    if var_name_sel6_chkpt not in locals():\n",
        "        print(f\"‚ùå ERROR FATAL: Variabel '{var_name_sel6_chkpt}' tidak terdefinisi!\")\n",
        "        all_vars_present_sel6_cpu_chkpt = False\n",
        "if not all_vars_present_sel6_cpu_chkpt:\n",
        "    raise NameError(\"Satu atau lebih variabel penting tidak terdefinisi untuk SEL 6.\")\n",
        "else:\n",
        "    print(\"‚úÖ Semua variabel yang dibutuhkan untuk SEL 6 tersedia.\")\n",
        "\n",
        "# --- [DIUBAH] Pemilihan File Konfigurasi Dasar ke PP-OCRv4 Mobile ---\n",
        "base_repo_path_sel6_chkpt = \"/content/PaddleOCR_Official\" # Pastikan path ini benar\n",
        "# Kita menggunakan config yang ringan dan cepat, cocok untuk Raspberry Pi\n",
        "BASE_CFG_PATH_SEL6_chkpt = os.path.join(base_repo_path_sel6_chkpt, 'configs/rec/PP-OCRv4/PP-OCRv3_mobile_rec.yml')\n",
        "print(f\"‚ÑπÔ∏è Menggunakan file konfigurasi dasar baru: {BASE_CFG_PATH_SEL6_chkpt}\")\n",
        "\n",
        "if not os.path.exists(BASE_CFG_PATH_SEL6_chkpt):\n",
        "    print(f\"‚ùå Error: File config dasar PP-OCRv4 tidak ditemukan di: {BASE_CFG_PATH_SEL6_chkpt}\")\n",
        "    raise FileNotFoundError(\"File config dasar PP-OCRv4 tidak ditemukan. Pastikan repo PaddleOCR ter-clone dengan benar.\")\n",
        "\n",
        "# --- [DIUBAH] Nama file konfigurasi custom yang baru ---\n",
        "CUSTOM_CFG_PATH_SEL6_chkpt = os.path.join(os.getcwd(), 'rec_ppocrv4_pi5.yml')\n",
        "os.makedirs(os.path.dirname(CUSTOM_CFG_PATH_SEL6_chkpt), exist_ok=True)\n",
        "print(f\"‚ÑπÔ∏è Menyalin '{BASE_CFG_PATH_SEL6_chkpt}' ke '{CUSTOM_CFG_PATH_SEL6_chkpt}'...\")\n",
        "!cp -f \"{BASE_CFG_PATH_SEL6_chkpt}\" \"{CUSTOM_CFG_PATH_SEL6_chkpt}\"\n",
        "print(\"‚úÖ File konfigurasi disalin.\")\n",
        "\n",
        "# --- Baca dan Modifikasi YAML ---\n",
        "with open(CUSTOM_CFG_PATH_SEL6_chkpt, 'r', encoding='utf-8') as f_y6_chkpt:\n",
        "    yaml_cfg_6_chkpt = yaml.safe_load(f_y6_chkpt)\n",
        "\n",
        "# --- Penyesuaian Konfigurasi Global ---\n",
        "yaml_cfg_6_chkpt['Global']['use_gpu'] = False\n",
        "print(\"‚ÑπÔ∏è Global.use_gpu diatur ke False untuk training CPU.\")\n",
        "\n",
        "yaml_cfg_6_chkpt['Global']['epoch_num'] = 100 # PP-OCRv4 butuh epoch lebih banyak untuk konvergen\n",
        "SAVED_MODEL_DIR_SEL6 = \"./output/rec_ppocrv4_mobile_checkpoint\" # Direktori output baru\n",
        "\n",
        "os.makedirs(SAVED_MODEL_DIR_SEL6, exist_ok=True)\n",
        "\n",
        "yaml_cfg_6_chkpt['Global']['save_model_dir'] = SAVED_MODEL_DIR_SEL6\n",
        "yaml_cfg_6_chkpt['Global']['eval_batch_step'] = [0, 2000] # Evaluasi setiap 2000 step\n",
        "yaml_cfg_6_chkpt['Global']['use_space_char'] = SETTING_USE_SPACE_CHAR_SEL4\n",
        "yaml_cfg_6_chkpt['Global']['max_text_length'] = 50\n",
        "\n",
        "# --- [FIX KRITIS] Menggunakan PATH RELATIF untuk portabilitas ---\n",
        "# Asumsikan file kamus dan label ada di dalam `COLAB_PROCESSED_RECO_DATA_DIR_SEL2`\n",
        "# Kita akan membuat path relatif dari lokasi file yml.\n",
        "relative_data_path = os.path.relpath(COLAB_PROCESSED_RECO_DATA_DIR_SEL2, os.path.dirname(CUSTOM_CFG_PATH_SEL6_chkpt))\n",
        "relative_char_dict_path = os.path.relpath(path_char_dict_output_sel4, os.path.dirname(CUSTOM_CFG_PATH_SEL6_chkpt))\n",
        "\n",
        "print(f\"‚ÑπÔ∏è Mengkonversi path absolut ke path relatif untuk portabilitas...\")\n",
        "yaml_cfg_6_chkpt['Global']['character_dict_path'] = relative_char_dict_path\n",
        "\n",
        "# --- LOGIKA CHECKPOINT YANG DIPERBAIKI (TETAP SAMA) ---\n",
        "checkpoint_files = {\n",
        "    'params': os.path.join(SAVED_MODEL_DIR_SEL6, \"latest.pdparams\"),\n",
        "    'opt': os.path.join(SAVED_MODEL_DIR_SEL6, \"latest.pdopt\"),\n",
        "}\n",
        "all_checkpoint_files_exist = all(os.path.exists(f) for f in checkpoint_files.values())\n",
        "\n",
        "if all_checkpoint_files_exist:\n",
        "    print(\"\\n‚úÖ Checkpoint lengkap ditemukan.\")\n",
        "    yaml_cfg_6_chkpt['Global']['checkpoints'] = os.path.join(SAVED_MODEL_DIR_SEL6, \"latest\")\n",
        "    if 'pretrained_model' in yaml_cfg_6_chkpt['Global']:\n",
        "        del yaml_cfg_6_chkpt['Global']['pretrained_model']\n",
        "    print(\"\\n‚ö†Ô∏è Akan melanjutkan training dari checkpoint...\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Checkpoint tidak ditemukan. Training akan dimulai dari awal.\")\n",
        "    yaml_cfg_6_chkpt['Global'].pop('checkpoints', None)\n",
        "    # Hapus pretrained_model bawaan dari config file agar training murni dari data kita\n",
        "    yaml_cfg_6_chkpt['Global'].pop('pretrained_model', None)\n",
        "\n",
        "# --- [DIUBAH] Penyesuaian Arsitektur & Optimizer untuk PP-OCRv4 ---\n",
        "# Arsitektur sudah benar dari file dasar, kita hanya perlu menyesuaikan jumlah kelas output\n",
        "num_classes = len(sorted_chars_final_sel4)\n",
        "if SETTING_USE_SPACE_CHAR_SEL4:\n",
        "    num_classes += 1\n",
        "# +1 untuk blank character CTC\n",
        "yaml_cfg_6_chkpt['Architecture']['Head']['out_channels'] = num_classes + 1\n",
        "print(f\"‚úÖ Arsitektur Head diatur ke {num_classes + 1} kelas output.\")\n",
        "\n",
        "# Optimizer yang lebih cocok untuk arsitektur SVTR (PP-OCRv4)\n",
        "yaml_cfg_6_chkpt['Optimizer'] = {\n",
        "    'name': 'Adam',\n",
        "    'beta1': 0.9,\n",
        "    'beta2': 0.999,\n",
        "    'lr': {\n",
        "        'name': 'Cosine',\n",
        "        'learning_rate': 0.0005,\n",
        "        'warmup_epoch': 2\n",
        "    },\n",
        "    'regularizer': {'name': 'L2', 'factor': 0.00001}\n",
        "}\n",
        "print(\"‚úÖ Optimizer diatur ke Adam dengan Cosine LR Scheduler.\")\n",
        "\n",
        "# --- [DIUBAH] Transformasi Gambar untuk PP-OCRv3 ---\n",
        "# PP-OCRv4 (SVTR) menggunakan 'SVTRRecResizeImg'\n",
        "img_shape_sel6_chkpt = [3, 48, 320]\n",
        "print(f\"‚ÑπÔ∏è Mengatur image_shape ke: {img_shape_sel6_chkpt}\")\n",
        "\n",
        "def update_svtr_resize_cfg(transforms, shape):\n",
        "    if transforms is None: return False\n",
        "    for t_cfg in transforms:\n",
        "        if 'SVTRRecResizeImg' in t_cfg:\n",
        "            t_cfg['SVTRRecResizeImg']['image_shape'] = shape\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "if not update_svtr_resize_cfg(yaml_cfg_6_chkpt['Train']['dataset']['transforms'], img_shape_sel6_chkpt):\n",
        "    print(\"‚ö†Ô∏è ResizeImg TDK diupdate di Train.\")\n",
        "if 'Eval' in yaml_cfg_6_chkpt and yaml_cfg_6_chkpt['Eval'].get('dataset') and \\\n",
        "   not update_svtr_resize_cfg(yaml_cfg_6_chkpt['Eval']['dataset']['transforms'], img_shape_sel6_chkpt):\n",
        "    print(\"‚ö†Ô∏è RecResizeImg TDK diupdate di Eval.\")\n",
        "\n",
        "\n",
        "# --- DataLoader Training (menggunakan path relatif) ---\n",
        "yaml_cfg_6_chkpt['Train']['dataset']['data_dir'] = relative_data_path\n",
        "yaml_cfg_6_chkpt['Train']['dataset']['label_file_list'] = [os.path.basename(output_train_label_reco_file_sel3)]\n",
        "yaml_cfg_6_chkpt['Train']['loader']['batch_size_per_card'] = 64 # Bisa dinaikkan untuk CPU\n",
        "yaml_cfg_6_chkpt['Train']['loader']['num_workers'] = 2 # Di Colab bisa pakai 2\n",
        "yaml_cfg_6_chkpt['Train']['loader']['shuffle'] = True\n",
        "\n",
        "# --- DataLoader Evaluasi (menggunakan path relatif) ---\n",
        "if 'Eval' in yaml_cfg_6_chkpt:\n",
        "    if os.path.exists(output_val_label_reco_file_sel3) and num_val_labels_final_sel3 > 0:\n",
        "        yaml_cfg_6_chkpt['Eval']['dataset']['data_dir'] = relative_data_path\n",
        "        yaml_cfg_6_chkpt['Eval']['dataset']['label_file_list'] = [os.path.basename(output_val_label_reco_file_sel3)]\n",
        "        yaml_cfg_6_chkpt['Eval']['loader']['batch_size_per_card'] = 64\n",
        "        yaml_cfg_6_chkpt['Eval']['loader']['num_workers'] = 2\n",
        "        print(\"‚úÖ Konfigurasi Eval disesuaikan dengan path relatif.\")\n",
        "    else:\n",
        "        if 'Eval' in yaml_cfg_6_chkpt:\n",
        "            del yaml_cfg_6_chkpt['Eval']\n",
        "        print(\"‚ÑπÔ∏è Konfigurasi Eval dihapus karena data validasi tidak ditemukan.\")\n",
        "\n",
        "# Hapus section yang tidak perlu\n",
        "if 'Test' in yaml_cfg_6_chkpt:\n",
        "    del yaml_cfg_6_chkpt['Test']\n",
        "    print(\"‚ÑπÔ∏è Konfigurasi Test dihapus.\")\n",
        "\n",
        "# --- Simpan Konfigurasi ---\n",
        "with open(CUSTOM_CFG_PATH_SEL6_chkpt, 'w', encoding='utf-8') as f_y_out_6_chkpt:\n",
        "    yaml.dump(yaml_cfg_6_chkpt, f_y_out_6_chkpt, sort_keys=False, allow_unicode=True)\n",
        "\n",
        "print(f\"\\n‚úÖ Konfigurasi baru berhasil disimpan di: {CUSTOM_CFG_PATH_SEL6_chkpt}\")\n",
        "print(\"=\"*60)\n",
        "print(\"Isi Konfigurasi Akhir:\")\n",
        "!cat \"{CUSTOM_CFG_PATH_SEL6_chkpt}\"\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nüéâ SEL 6: Modifikasi File Konfigurasi YAML Selesai!\")"
      ],
      "metadata": {
        "id": "4mbpqxIUgfkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DOWNLOAD FILE PPOCRv3 UNTUK FINE TUNING\n",
        "\n",
        "%cd /content/PaddleOCR_Official\n",
        "\n",
        "# Unduh file model pre-trained\n",
        "print(\"Downloading pre-trained model...\")\n",
        "!wget https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_rec_train.tar\n",
        "\n",
        "# Ekstrak file .tar tersebut\n",
        "print(\"\\nExtracting model...\")\n",
        "!tar -xf en_PP-OCRv3_rec_train.tar\n",
        "\n",
        "# Verifikasi hasilnya, Anda sekarang seharusnya memiliki folder baru bernama 'en_PP-OCRv3_rec_train'\n",
        "print(\"\\nExtraction complete. Directory contents:\")\n",
        "!ls -l"
      ],
      "metadata": {
        "id": "UOyTCZ7zguBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KONFIGURASI CHECKPOINT\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "from threading import Thread\n",
        "\n",
        "# 1. Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Folder Backup Khusus\n",
        "BACKUP_DIR = \"/content/drive/MyDrive/OCR_Training_Backup\"\n",
        "os.makedirs(BACKUP_DIR, exist_ok=True)\n",
        "\n",
        "# 3. File Penting yang Harus Dibackup\n",
        "ESSENTIAL_FILES = [\n",
        "    \"/content/PaddleOCR_Official/output/\",  # Folder model\n",
        "    \"/content/PaddleOCR_Official/train.log\",  # Log training\n",
        "    \"/content/processed_data/train_label.txt\",  # Label\n",
        "    \"/content/config.yml\"  # Konfigurasi\n",
        "]\n",
        "\n",
        "def selective_backup():\n",
        "    while True:\n",
        "        try:\n",
        "            # Backup file penting\n",
        "            for file in ESSENTIAL_FILES:\n",
        "                if os.path.exists(file):\n",
        "                    if os.path.isdir(file):\n",
        "                        shutil.copytree(file, f\"{BACKUP_DIR}/{os.path.basename(file)}\", dirs_exist_ok=True)\n",
        "                    else:\n",
        "                        shutil.copy2(file, BACKUP_DIR)\n",
        "\n",
        "            # Kompresi untuk hemat space\n",
        "            !tar -czf \"{BACKUP_DIR}/backup_{int(time.time())}.tar.gz\" -C \"{BACKUP_DIR}\" .\n",
        "            !rm -rf \"{BACKUP_DIR}/output\" \"{BACKUP_DIR}/train.log\"  # Hapus duplikat\n",
        "\n",
        "            print(f\"‚úÖ Backup sukses: {time.ctime()}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Gagal backup: {e}\")\n",
        "\n",
        "        time.sleep(1800)  # Backup setiap 30 menit\n",
        "\n",
        "# Jalankan di background\n",
        "backup_thread = Thread(target=selective_backup, daemon=True)\n",
        "backup_thread.start()"
      ],
      "metadata": {
        "id": "qNm-zbiGgxXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MEMULAI PELATIHAN DENGAN RESUME CHECKPOINT\n",
        "\n",
        "print(\"\\n\\nüöÄ SEL 7: Memulai Pelatihan Model...\")\n",
        "\n",
        "# 1. Verifikasi environment\n",
        "print(\"üîç Verifikasi Environment:\")\n",
        "print(f\"Working Directory: {os.getcwd()}\")\n",
        "print(\"Isi output folder:\")\n",
        "!ls -lh \"./output\"\n",
        "\n",
        "# 2. Siapkan perintah training\n",
        "train_cmd = f'python tools/train.py -c \"{CUSTOM_CFG_PATH_SEL6_chkpt}\"'  # Menggunakan variabel yang benar\n",
        "\n",
        "# 3. Tambahkan parameter resume jika checkpoint ada\n",
        "checkpoint_path = os.path.join(SAVED_MODEL_DIR_SEL6, \"latest.pdparams\")  # Menggunakan variabel yang benar\n",
        "if os.path.exists(checkpoint_path):\n",
        "    train_cmd += f' -o Global.checkpoints=\"{os.path.join(SAVED_MODEL_DIR_SEL6, \"latest\")}\"'  # Menggunakan variabel yang benar\n",
        "    print(f\"‚úÖ Akan melanjutkan dari checkpoint: {checkpoint_path}\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Tidak ditemukan checkpoint, training dari awal\")\n",
        "\n",
        "# 4. Jalankan training\n",
        "print(f\"\\nüöÄ Menjalankan perintah:\\n{train_cmd}\")\n",
        "!{train_cmd}\n",
        "\n",
        "print(\"\\nüéâ SEL 7: Proses Training Selesai!\")"
      ],
      "metadata": {
        "id": "0cCl211tgyLW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}